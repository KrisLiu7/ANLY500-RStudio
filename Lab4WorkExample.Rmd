---
title: "Workexample"
author: "Zimo Liu"
date: "February 25, 2019"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(haven)
```

# Abstract

This study investigated associations between working memory (measured by complex memory tasks) and both reading and mathematics abilities, as well as the possible mediating factors of fluid intelligence, verbal abilities, short-term memory (STM), and phonological awareness, in a sample of 6- to 11-year-olds with reading disabilities. As a whole, the sample was characterized by deficits in complex memory and visuospatial STM and by low IQ scores; language, phonological STM, and phonological awareness abilities fell in the low average range. Severity of reading difficulties within the sample was significantly associated with complex memory, language, and phonological awareness abilities, whereas poor mathematics abilities were linked with complex memory, phonological STM, and phonological awareness scores. These findings suggest that working memory skills indexed by complex memory tasks represent an important constraint on the acquisition of skill and knowledge in reading and mathematics. Possible mechanisms for the contribution of working memory to learning, and the implications for educational practice, are considered.

*Citation:* Gathercole, S. E., Alloway, T. P., Willis, C., & Adams, A. M. (2006). Working memory in children with reading disabilities. Journal of Experimental Child Psychology, 93(3), 265-281.

# Dataset:

    -	Dependent variable (Y): Reading - reading skills of the 6 to 11 year olds
    -	Independent variables (X):
        - Verbal - a measure of verbal ability (spelling, phonetics, etc.)
        - Math - a measure of math ability
        - Work_mem - working memory score

```{r starting}
hdata = read_spss("WorkExampleOfLab4.sav")
head(hdata)
```

# Data screening:

## Accuracy

Assume the data is accurate with no missing values. You will want to screen the dataset using all the predictor variables to predict the outcome in a simultaneous multiple regression (all the variables at once). This analysis will let you screen for outliers and assumptions across all subsequent analyses/steps.

## Outliers
    
    a.	Leverage:
        i.	What is your leverage cut off score?
        ii.	How many leverage outliers did you have?

```{r leverage}
fit=lm(reading~verbal+math+work_mem,data=hdata)
leverage = hatvalues(fit)
k=3
cutleverage = (2*k+2) / nrow(hdata)
badleverage = as.numeric(leverage > cutleverage)
table(badleverage)
```

As can be seen from the above results,the leverage cut off score is 0.0026,and we have 247 leverage outliers.

    b.	Cook's:
        i.	What is your Cook's cut off score?
        ii.	How many Cook's outliers did you have?
        
```{r cooks}
cooks = cooks.distance(fit)
cutcooks = 4 / (nrow(hdata) - k - 1)
badcooks = as.numeric(cooks > cutcooks)
table(badcooks)
```

As can be seen from the above results,the Cook's cut off score is 0.0013,and we have 149 Cook's outliers.

    c.	Mahalanobis:
        i.	What is your Mahalanobis df?
        ii.	What is your Mahalanobis cut off score?
        iii.	How many outliers did you have for Mahalanobis?
        
```{r mahal}
mahal = mahalanobis(hdata, 
                    colMeans(hdata), 
                    cov(hdata))
cutmahal = qchisq(1-.001, ncol(hdata))
badmahal = as.numeric(mahal > cutmahal) ##note the direction of the > 
table(badmahal)
```

As can be seen from the above results,the Mahalanobis df is 4,the Mahalanobis cut off score 18.4668,and we have 82 outliers for Mahalanobis.

       
    d.	Overall:
        i.	How many total outliers did you have across all variables?
        ii.	Delete them!

```{r overall}
totalout = badmahal + badleverage + badcooks
table(totalout)
rem=badmahal+badleverage + badcooks
remrow=ifelse(rem==0,TRUE,FALSE)
remhdata=hdata[remrow,]
head(remhdata)
```

As can be seen from the above results,we have 320 outliers.

totalout = badmahal + badleverage + badcooks
   table(totalout)

# Hierarchical Regression:

    a.	In step 1, control for verbal ability of the participant predicting reading scores. 
    b.	In step 2, test if working memory is related to reading scores.
    c.	In step 3, test if math score is related to reading scores.
    d.  Include the summaries of each step, along with the ANOVA of the change between each step.

```{r hierarchical}
model1 = lm(reading ~ verbal, data = remhdata)
summary(model1)
model2 = lm(reading ~ verbal+work_mem, data = remhdata)
summary(model2)
anova(model1, model2)
model3 = lm(reading ~ verbal+work_mem+math, data = remhdata)
summary(model3)
anova(model2, model3)
```

By adding friends,the model accounts for additional SS(Sum of Squre) 54.083 and it was a statistically significant change according to the corresponding F-statistic and p-value.In other words, the second model is better than the first model.By adding math,the model accounts for additional SS 20.957 and it was statistically significant again.In other words, the third model is better than the second model
From the regression results of Model 3, the regression coefficient of ‘work_mem’ is 0.001815, the t value is 0.897, and the p value is greater than the generally required significance level of 0.05.That is,this variable may have no significant effect on ‘reading’.However,the regression coefficient of 'math' is 0.0052, the t value is 5.097, and the corresponding p value is less than 0.001, that is, 'math' has a significant positive influence on 'reading'.

# Moderation:

    a. Examine the interaction between verbal and math scores predicting reading scores.
    b. Include the simple slopes for low, average, and high math levels (split on math) for verbal predicting reading. 
    c. Include a graph of the interaction. 

```{r moderation}
remhdata$zver = scale(remhdata$verbal, scale = FALSE) #mean center, not z score
remhdata$zmat = scale(remhdata$math, scale = FALSE)

modmodel = lm(reading ~ zver*zmat, data = remhdata)
summary(modmodel)
remhdata$zmatlow = remhdata$zmat - sd(remhdata$zmat) #bring them down
remhdata$zmathigh = remhdata$zmat + sd(remhdata$zmat) #bring them up
summary(remhdata)

modmodellow = lm(reading ~ zver*zmatlow, data = remhdata)
modmodelhigh = lm(reading ~ zver*zmathigh, data = remhdata)
summary(modmodellow) #low slope
summary(modmodel) #average slope
summary(modmodelhigh) #high slope
####graph####
library(ggplot2)

cleanup = theme(panel.grid.major = element_blank(), 
                panel.grid.minor = element_blank(), 
                panel.background = element_blank(), 
                axis.line.x = element_line(color = "black"),
                axis.line.y = element_line(color = "black"),
                legend.key = element_rect(fill = "white"),
                text = element_text(size = 15))
modgraph = ggplot(remhdata, aes(zver, reading))
modgraph + 
  xlab("Verbal.ability") + 
geom_point(color = "gray") +
geom_abline(aes(intercept = modmodellow$coefficients[1],
                  slope = modmodellow$coefficients[2], 
                  linetype = "-1SD.Math"), size = 1) +
geom_abline(aes(intercept = modmodel$coefficients[1],
                  slope = modmodel$coefficients[2], 
                  linetype = "Average.Math"), size = 1) +
geom_abline(aes(intercept = modmodelhigh$coefficients[1],
                  slope = modmodelhigh$coefficients[2], 
                  linetype = "+1SD.Math"), size = 1)+
cleanup 
```

It can be seen from the above results that the regression coefficient of the interaction term in the model is -0.0005, and the corresponding p value is less than 0.05.That is to say, at the 5% significance level, the regression coefficient is significantly different from the value of 0.The stronger the mathematics ability, the more the reading skill is reduced by 0.0005 units for each additional unit of verbal ability.In other words, there is an interaction between mathematical ability and verbal ability.